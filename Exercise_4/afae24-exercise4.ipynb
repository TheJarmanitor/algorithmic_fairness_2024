{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12394aa1-0fe2-49d1-951a-6defb73ef28c",
   "metadata": {},
   "source": [
    "# Algorithmic Fairness, Accountability, and Ethics, Spring 2024\n",
    "# Exercise 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccc72700",
   "metadata": {},
   "source": [
    "## Task 0 (Setup)\n",
    "\n",
    "We use the same dataset as in week 2 and 3. If you missed to install the module, please carry out the installation tasks at <https://github.com/zykls/folktables#basic-installation-instructions>.\n",
    "\n",
    "After successful installation, you should be able to run the following code to generate a prediction task.\n",
    "To make your life easier, we made the `BasicProblem`-magic from the `folktables` package (see exercises of week 2) explicit in this task.\n",
    "This way, you can get access to different encodings of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5921f706-cf73-4c13-a7da-0448ef057d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 2018 1-Year person survey for CA...\n"
     ]
    }
   ],
   "source": [
    "from folktables.acs import adult_filter\n",
    "from folktables import ACSDataSource\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person', root_dir=\"/mnt/storage/Datasets/folktables\")\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "\n",
    "feature_names = ['AGEP', # Age\n",
    "                 \"CIT\", # Citizenship status\n",
    "                 'COW', # Class of worker\n",
    "                 \"ENG\", # Ability to speak English\n",
    "                 'SCHL', # Educational attainment\n",
    "                 'MAR', # Marital status\n",
    "                 \"HINS1\", # Insurance through a current or former employer or union\n",
    "                 \"HINS2\", # Insurance purchased directly from an insurance company\n",
    "                 \"HINS4\", # Medicaid\n",
    "                 \"RAC1P\", # Recoded detailed race code\n",
    "                 'SEX']\n",
    "\n",
    "target_name = \"PINCP\" # Total person's income\n",
    "\n",
    "def data_processing(data, features, target_name:str, threshold: float = 35000):\n",
    "    df = data\n",
    "    ### Adult Filter (STARTS) (from Foltktables)\n",
    "    df = df[~df[\"SEX\"].isnull()]\n",
    "    df = df[~df[\"RAC1P\"].isnull()]\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    ### Adult Filter (ENDS)\n",
    "    ### Groups of interest\n",
    "    sex = df[\"SEX\"].values\n",
    "    ### Target\n",
    "    df[\"target\"] = df[target_name] > threshold\n",
    "    target = df[\"target\"].values\n",
    "    df = df[features + [\"target\", target_name]] ##we want to keep df before one_hot encoding to make Bias Analysis\n",
    "    df_processed = df[features].copy()\n",
    "    cols = [ \"HINS1\", \"HINS2\", \"HINS4\", \"CIT\", \"COW\", \"SCHL\", \"MAR\", \"SEX\", \"RAC1P\"]\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=False, columns=cols, drop_first=True)\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=True, columns=[\"ENG\"], drop_first=True)\n",
    "    return df_processed, df, target, sex\n",
    "\n",
    "data, data_original, target, group = data_processing(acs_data, feature_names, target_name)\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    data, target, group, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc7dad",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "1. Train a black-box model classifier (for example, use a random forest, a gradient-boosted decision tree, an SVM, or a Neural Network). Report on its accuracy. If you have used a tree data structure such as RF or gradient-boosted decision trees, report on the feature importance.\n",
    "2. Use the `shap` module to explain predictions on your black-box model. Do the same with a white-box model that you have trained during last week's exercises. Contrast the two models to each other: What are similarities, how do they differ? As shown in the lecture, provide a summary plot, a dependence plot,  a  force plot for a negatively/positively predicted feature vector, and summary plot on the interaction values.\n",
    "3. Reflect on the explanations: How does the white box models's (from last week) black-box explanation relate to its white-box explanation? Which classifier would you prefer when deploying a model as part of the machine learning pipeline? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fce266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## change boolean to int\n",
    "y_train = y_train.astype(int)\n",
    "X_train = X_train.astype(int)\n",
    "\n",
    "X_test = X_test.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a63be5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "## pytorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "## dataloaders for tabular data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "## function to detect gpu\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "print(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "753efc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 55]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "##  trainloader and testloader\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "##trainloader from numpy\n",
    "\n",
    "train_data = TensorDataset(torch.tensor(X_train.values, dtype=torch.float32), \n",
    "                           torch.tensor(y_train, dtype=torch.float32))\n",
    "\n",
    "test_data = TensorDataset(torch.tensor(X_test.values, dtype=torch.float32),\n",
    "                            torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "## testing dataloader\n",
    "\n",
    "features, target = next(iter(trainloader))\n",
    "\n",
    "print(features.shape, target.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7adee077",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mlp class\n",
    "class MLP_model(nn.Module):\n",
    "    def __init__(self, input_nodes, out_nodes) -> None:\n",
    "        super(MLP_model, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(input_nodes, 64)\n",
    "        self.layer_2 = nn.Linear(64, 16)\n",
    "        self.output = nn.Linear(16, out_nodes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33573b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP_model(\n",
       "  (layer_1): Linear(in_features=55, out_features=64, bias=True)\n",
       "  (layer_2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (output): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP_model(X_train.shape[1], 2)\n",
    "model.to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc04e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "495613e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "90245f237ffeb45287c33c260238522010c806ee942870b1ad6ce10064a8bcac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
